---
title: "Causal Network Data Cleaning"
author: "Galen Holt"
format:
  html:
    df-print: paged
editor: visual
params:
  REBUILD_DATA: FALSE
---

```{r setup}
#| warning: false
#| message: false
#| echo: false

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

```{r}
library(dplyr)

# library(werptoolkitr) works when running interactively, but not when quarto
# rendering. Just use load_all for now.
# Also have to turn off caching and delete _cache directories or it gets really
# upset.
devtools::load_all()
# library(werptoolkitr)
```

## TO REBUILD
Rebuilding data is done with params. To rebuild, at the terminal run
`quarto render data_creation/causal_data_cleaning.qmd -P REBUILD_DATA:TRUE`

## Purpose

This document walks through the data arrangement to get from a number of spreadsheets into usable data relationships. In general, it should *only* be updated if those spreadsheets change or the output needs to be in a different format.

This is used to go from the raw spreadsheets in `data-raw/` and online to clean versions in `data/` that are then used for the rest of the relationships.

First, do we actually want to rebuild the `data/` directory, or just use this to investigate and document what happened? All the functions here have a `saveout` argument that can be `FALSE`, so just set that conditionally.

Set with params. But that doesn't work with interactive running, so deal with that.

```{r}
if ("params" %in% ls()) {
  REBUILD_DATA <- params$REBUILD_DATA
} else {
  REBUILD_DATA <- FALSE
}

# `saver` is for individual functions. Probably shouldn't use it.
saver <- FALSE
```

## Data linking theme scales

The causal networks describe a complex set of many-to-many relationships between outcomes at various 'Theme' scales. For example, EWR conditions affect specific environmental objectives, which then feed in to determine species targets, targets for ecological groups (Fish, Waterbirds, etc), future planning targets, etc.

These relationships are therefore necessary to define for the causal network, but also for aggregation along the Theme dimension- how do we aggregate EWRs into objectives, for example. This step was originally titled 'Objective Translator', but the tight relationship with the causal network and the multiple scales has led to a much more general development beyond the initial scope of EWRs to proximate environmental objectives.

This notebook demonstrates the processing and creation of standard-format data linking indicators and outcomes across the theme dimension for the Environmental theme. These data are then used in the creation of causal networks and in the theme aggregation.

Incorporation of other themes as they come online can follow a similar process, with two key things to note- 1) building from the ground up could save a lot if the links were specified more cleanly in the original data, and 2) the precise number of links, their names, and relationships will need to differ simply because of differing causal relationships, and so each theme will need its own processing code- we can't simply plug new data in.

### Structure

This is a demonstration notebook for what this code does. It is likely that when we're actually running the toolkit, we'll want to run all of this automatically. That may be less likely with the causal network than with the pieces in the direct flow from hydrology to comparison, but should be possible by either writing a wrapper function to do what's in here and calling that from whatever the previous step is or calling this notebook itself as a script, though that's clunkier.

### Data information

The ingested data here is idiosyncratic and messy, and subject to change. Thus, the functions called here are highly dependent on the exact data being read in, and will need to change with new input data. The rest of the codebase should be relatively insensitive to these changes, provided new versions continue to produce outputs of the same format. The possible exception is if new relationships are described, but even that will require only minor changes.

#### Provenance

The code here currently reads the EWR definitions table from the MDBA, the table of watering plans obtained from the MDBA, and three files I have been unable to find origins for. I will keep hunting for their source and make them programatically if possible. For now let's assume they're roughly right, wherever they came from.

## Using the code

### User inputs

These will need to be set whether used as a notebook or be passed in as arguments to a wrapper function. They just set the location of the relevant input files and creates a directory for the outputs. Once on the MDBA system, this might be able to be hardcoded, or at least given default values. *I'm setting it up currently as is standard practice for an R package*.

```{r}
datarawdir <- 'data-raw/causal_networks'
dataoutdir <- 'data'

if (!dir.exists(dataoutdir)) {dir.create(dataoutdir, recursive = TRUE)} 
```

Known file sources- the ewr definitions and the ltwp table.

**UPDATE** 12/12/22: The data stream from MDBA has changed format and no longer can be matched against the table. Reverting to an old version. No guarantees about completeness.

**UPDATE** 20/12/22: A better solution is the NSW version that Lara has just sent. Get that included soon.

```{r}
# Get ewr defs from MDBA- This is a cached version, since WatReqID has gone
ewrs <- file.path(datarawdir, 'ewr_cache', 'NSWEWR_LIVE.csv')
  
# ewrs <- 'https://az3mdbastg001.blob.core.windows.net/mdba-public-data/NSWEWR_LIVE.csv'

# The links to objectives come from here (as do the ewrs themselves)
objtable <- file.path(datarawdir, 'tbl10', "tbl10a_WatRequirements5.4.csv")
```

Unknown file sources- these give nearly all links above environmental objectives (Theme group, Species, yearly targets). Some incorporate manual QC by Renee, but it's still not clear where the originals came from either sometimes.

```{r}
tarpath <- file.path(datarawdir, 'unknown', "Env_objectives_Target_species_nodes.csv")

qcs <- c(file.path(datarawdir, 'unknown', "Target_species_per_PU_Murray.csv"),
         file.path(datarawdir, 'unknown', "PUs.csv"))

timepath <- file.path(datarawdir, 'unknown', "Env_objectives_5_10_20_year_targets_nodes Murray Lower Darling.csv")
```

Do we want to look at those? They're pretty ugly. Easy enough to throw a cell in here if so.

### Make clean data

These are bespoke functions that deal with the specific datasets we're reading in and clean them up (including quite a lot of extraction of environmental objectives from the water requirements table).

The resulting dataframes provide links among different outcomes at different theme levels, and are available at different geographic scales (gauges, planning unit, basin). These dfs are database-like in that they specify relationships between variables and can be joined, filtered, etc. I have not made them a formal database for simplicity. Given the format of the input data and the needed format of the output it didn't seem worth it, at least at this stage. While many are referenced to the environmental objective as the smallest theme scale, links can be made between all levels. E.g. the `obj2target` df allows links from environmental objectives to Targets or species-level (Specific_goal), we can also link Specific_goals to Targets.

I've gone back and forth on a saving default. I think I'll default to not save to avoid clutter, but assume that we will save when we have a real new updated version that other bits need to access (the plotting, the theme aggregator).

Links between EWRs and environmental objectives. This can be returned long or wide. Wide is basically a matrix of matches (plus info columns), while long is easier to actually use later on.

Question- should we be separating the EWR codes like CF1_H and CF1_C into columns for the main code and modifiers? I assume there was a reason for that?

```{r}

ewr2obj <- clean_ewr_obj(ewrpath = ewrs,
               objtablepath = objtable,
               returnformat = 'long',
               saveout = saver,
               outdir = datout,
               savename = "ewr_to_objectives_")
```

Clean links from Objectives to 'targets'

```{r}

obj2target <- clean_obj_target(ewrobjs = ewr2obj,
                               targetpath = tarpath,
                               qcfiles = qcs,
                               saveout = saver,
                               outdir = datout,
                               savename = "obj_to_target_")
```

Clean links from Objectives to long-term planning

```{r}
yrtarget <- clean_long_term(timepath,
                               saveout = saver,
                               outdir = datout,
                               savename = "obj_to_yrtarget_")
```

Looking forward to having more than just the EWRs, it's likely we'll want to be able to have each set of causal relationships packaged up into a single file, likely as a list. `saveRDS` allows reading in with a different name.

In analysis code, we should use saveRDS, but in the package the standard is rda with object of canonical name.

```{r}
causal_ewr <- list(ewr2obj = ewr2obj, obj2target = obj2target, obj2yrtarget = yrtarget)

if (REBUILD_DATA) {
  usethis::use_data(causal_ewr, overwrite = TRUE)
  # saveRDS(causal_ewr,
  #    file = file.path(datout, 'causal_ewr.rds'))
}

```

I think rather than a wrapper, we leave this as a long qmd/script, so we can see where the data is coming from and it's processing- this isn't analysis, it's background package work.

### What do those look like?

The ewr to objective mapping has every ewr-objective pairing at each gauge, as well as some other useful reference data, such as the planning unit which allows cross-linking gauges to planning units. This is necessary for later matching with the `obj2target`, which is defined at the planning unit scale.

```{r}
# bit of column shuffle for readability
ewr2obj |> dplyr::select(gauge, ewr_code, env_obj, PlanningUnitID, everything())
```

The `obj2target` dataset links the `env_obj` to several different outcomes- `Specific_goal` (roughly species, but also things like refugia), `Objective` (which is an unfortunate name, this one is bigger-picture, e.g. no loss of native fish species), and `Target`, which are broad environmental themes (Native Fish, Ecosystem Function, etc).

```{r}
# rearrange for readability
obj2target |> dplyr::select(PlanningUnitID, env_obj, Specific_goal, Objective, Target, everything())
```

The `yrtarget` dataset has environmental objectives mapped to `Target` and `Objective` (again), and the 5, 10, and 20 year targets. This is not referenced to either gauges or Planning Units.

```{r}
yrtarget |> dplyr::select(env_obj, Target, Objective, tidyselect::starts_with('target'), everything())
```

### Next

This data then gets used in the causal networks and theme aggregation. I have a function that creates all the mappings across these datsets for a selection of outcomes of interest and potentially geographically filtered. That needs to happen for both the causal networks and the theme aggregation, but I'm hesitant to do it here as a last step because I want this data processing part to produce general, complete data. Maintaining that generality will be massive if we go for the edges at this point.

Primarily, this is because the potential mappings are large- within the `obs2target` df, for example, we could match `env_code` to `Specific_goal` `Objective`, and `Target`, `Specific_goal` to `Objective` and `Target`, and `Objective` to `Target`. Rather than doing a massive fully-factorial join with all possibilities here, it is better to expose that function to downstream uses where we can define *which* mappings we actually want.

## Still to do

-   Get rid of the library calls and reference each function with `::`

-   Make this a library/package so I don't have to source a functions directory

    -   Or, make this a hidden part of another package?

    -   This sort of data cleaning isn't usually what a package does, but we do need it to be modular so we can update the functions when we get new input data, and expand to new themes.

    -   <https://r-pkgs.org/Data.html> suggests putting the data cleaning in `data-raw/` , putting that in `.Rbuildignore` and then exporting the clean data for the rest of the package into `data/`.

    -   I've done this, but it may or may not work well, depending on how the overall project gets broken up into packages- this data is needed by causal networks and the theme aggregator

    -   Similarly, where should this (and other) notebooks go? R packages don't typically distribute runnable examples, though it could be an option to make it a vignette? Otherwise, could a) not get all the way to a package or b) have the notebooks outside the package as a thing to get from github/website (e.g. as blog posts)

-   Move to MDBA

-   Sort out how to deal with newly-missing WatReqIDs

-   Tests

-   Figure out data provenance

-   QC (and long term, better input data)
